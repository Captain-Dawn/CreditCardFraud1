{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\Python\\MLProjectsPW\\CreditCardFraud1\\notebooks\\data\\creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate into independent and dependent features\n",
    "X = df.drop('Class',axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rectifying target imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "resampler = SMOTE(random_state=11)\n",
    "X , y = resampler.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((284315, 30), (284315, 30))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[y==1].shape , X[y==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols = X.columns\n",
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since all the features are only numerical in nature creating only numerical pipeline\n",
    "from sklearn.impute import SimpleImputer ## HAndling Missing Values\n",
    "from sklearn.preprocessing import StandardScaler # HAndling Feature Scaling\n",
    "## pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer',SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numerical_pipeline',numerical_pipeline , numerical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.DataFrame(preprocessor.fit_transform(X_train),columns=preprocessor.get_feature_names_out())\n",
    "X_test=pd.DataFrame(preprocessor.transform(X_test),columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398041, 30), (170589, 30))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import  accuracy_score , roc_auc_score , f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to evaluate the model\n",
    "def evaluate_model(true, predicted):\n",
    "    accuracy = accuracy_score(true, predicted)\n",
    "    roc_score = roc_auc_score(true, predicted)\n",
    "    f_1_score = f1_score(true, predicted)\n",
    "\n",
    "    return accuracy , roc_score , f_1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Model Training Performance\n",
      "ROC: 0.9271995610023779\n",
      "Accuracy: 0.9256756756756757\n",
      "===================================\n",
      "\n",
      "\n",
      "RidgeClassifier\n",
      "Model Training Performance\n",
      "ROC: 0.8882385220413391\n",
      "Accuracy: 0.8851351351351351\n",
      "===================================\n",
      "\n",
      "\n",
      "BernoulliNB\n",
      "Model Training Performance\n",
      "ROC: 0.9050210353027255\n",
      "Accuracy: 0.902027027027027\n",
      "===================================\n",
      "\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Model Training Performance\n",
      "ROC: 0.9158130601792573\n",
      "Accuracy: 0.9155405405405406\n",
      "===================================\n",
      "\n",
      "\n",
      "KNeighborsClassifier\n",
      "Model Training Performance\n",
      "ROC: 0.9144869215291751\n",
      "Accuracy: 0.9121621621621622\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoostClassifier\n",
      "Model Training Performance\n",
      "ROC: 0.9125663069325041\n",
      "Accuracy: 0.9121621621621622\n",
      "===================================\n",
      "\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Model Training Performance\n",
      "ROC: 0.9242271812694349\n",
      "Accuracy: 0.9222972972972973\n",
      "===================================\n",
      "\n",
      "\n",
      "BaggingClassifier\n",
      "Model Training Performance\n",
      "ROC: 0.920157307481251\n",
      "Accuracy: 0.918918918918919\n",
      "===================================\n",
      "\n",
      "\n",
      "RandomForestClassifier\n",
      "Model Training Performance\n",
      "ROC: 0.9209804280226815\n",
      "Accuracy: 0.918918918918919\n",
      "===================================\n",
      "\n",
      "\n",
      "SVC\n",
      "Model Training Performance\n",
      "ROC: 0.9242271812694349\n",
      "Accuracy: 0.9222972972972973\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model Training Performance\n",
      "ROC: 0.9336930674958845\n",
      "Accuracy: 0.9324324324324325\n",
      "===================================\n",
      "\n",
      "\n",
      "Best Model ('XGBClassifier', 0.9324324324324325)\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "                        models  accuracy  roc_auc_score  f1_score\n",
      "10               XGBClassifier  0.932432       0.933693  0.932886\n",
      "0           LogisticRegression  0.925676       0.927200  0.925676\n",
      "6   GradientBoostingClassifier  0.922297       0.924227  0.921502\n",
      "9                          SVC  0.922297       0.924227  0.921502\n",
      "7            BaggingClassifier  0.918919       0.920157  0.919463\n",
      "8       RandomForestClassifier  0.918919       0.920980  0.917808\n",
      "3       DecisionTreeClassifier  0.915541       0.915813  0.918033\n",
      "4         KNeighborsClassifier  0.912162       0.914487  0.910345\n",
      "5           AdaBoostClassifier  0.912162       0.912566  0.914474\n",
      "2                  BernoulliNB  0.902027       0.905021  0.898246\n",
      "1              RidgeClassifier  0.885135       0.888239  0.880282\n"
     ]
    }
   ],
   "source": [
    "models={\n",
    "    'LogisticRegression':LogisticRegression(),\n",
    "    'RidgeClassifier':RidgeClassifier(),\n",
    "    'BernoulliNB':BernoulliNB(),\n",
    "    'DecisionTreeClassifier':DecisionTreeClassifier(),\n",
    "    'KNeighborsClassifier':KNeighborsClassifier(),\n",
    "    'AdaBoostClassifier':AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier':GradientBoostingClassifier(),\n",
    "    'BaggingClassifier':BaggingClassifier(),\n",
    "    'RandomForestClassifier':RandomForestClassifier(),\n",
    "    'SVC':SVC(),\n",
    "    'XGBClassifier':XGBClassifier()\n",
    "}\n",
    "model_list=[]\n",
    "roc=[]\n",
    "acc = []\n",
    "f1 = []\n",
    "performance = []\n",
    "for i in range(len(list(models))):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    #Make Predictions\n",
    "    y_pred=model.predict(X_test)\n",
    "\n",
    "    accuracy , roc_score  , f_1_score =evaluate_model(y_test,y_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    roc.append(roc_score)\n",
    "    acc.append(accuracy)\n",
    "    f1.append(f_1_score)\n",
    "    performance.append((list(models.keys())[i] , accuracy ))\n",
    "\n",
    "\n",
    "    print('Model Training Performance')\n",
    "    print(\"ROC:\",roc_score)\n",
    "    print(\"Accuracy:\",accuracy)\n",
    "\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')\n",
    "\n",
    "print(\"Best Model\" , sorted(performance , key = lambda x: x[1])[-1])\n",
    "model = models[sorted(performance , key = lambda x: x[1])[-1][0]]\n",
    "print(model)\n",
    "\n",
    "metrics = pd.DataFrame({\"models\": model_list , \"accuracy\" : acc , \"roc_auc_score\": roc , \"f1_score\" : f1})\n",
    "print(metrics.sort_values('accuracy',ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
