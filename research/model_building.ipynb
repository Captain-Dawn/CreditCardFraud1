{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\Python\\MLProjectsPW\\CreditCardFraud1\\notebooks\\data\\creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate into independent and dependent features\n",
    "X = df.drop('Class',axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rectifying target imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "resampler = SMOTE(random_state=42)\n",
    "X , y = resampler.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((284315, 30), (284315, 30))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[y==1].shape , X[y==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols = X.columns\n",
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since all the features are only numerical in nature creating only numerical pipeline\n",
    "from sklearn.impute import SimpleImputer ## HAndling Missing Values\n",
    "from sklearn.preprocessing import StandardScaler # HAndling Feature Scaling\n",
    "## pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer',SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numerical_pipeline',numerical_pipeline , numerical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.DataFrame(preprocessor.fit_transform(X_train),columns=preprocessor.get_feature_names_out())\n",
    "X_test=pd.DataFrame(preprocessor.transform(X_test),columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398041, 30), (170589, 30))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#from sklearn.ensemble import GradientBoostingClassifier\n",
    "#from sklearn.ensemble import BaggingClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import  accuracy_score , roc_auc_score , f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to evaluate the model\n",
    "def evaluate_model(true, predicted):\n",
    "    accuracy = accuracy_score(true, predicted)\n",
    "    roc_score = roc_auc_score(true, predicted)\n",
    "    f_1_score = f1_score(true, predicted)\n",
    "\n",
    "    return accuracy , roc_score , f_1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Model Training Performance\n",
      "ROC: 0.9805037229893587\n",
      "Accuracy: 0.9805204321497869\n",
      "===================================\n",
      "\n",
      "\n",
      "RidgeClassifier\n",
      "Model Training Performance\n",
      "ROC: 0.93280070681155\n",
      "Accuracy: 0.9328854732720163\n",
      "===================================\n",
      "\n",
      "\n",
      "BernoulliNB\n",
      "Model Training Performance\n",
      "ROC: 0.9198953725893483\n",
      "Accuracy: 0.9200065654878099\n",
      "===================================\n",
      "\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Model Training Performance\n",
      "ROC: 0.9983886322867245\n",
      "Accuracy: 0.9983879382609664\n",
      "===================================\n",
      "\n",
      "\n",
      "KNeighborsClassifier\n",
      "Model Training Performance\n",
      "ROC: 0.9989113002352996\n",
      "Accuracy: 0.9989096600601446\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoostClassifier\n",
      "Model Training Performance\n",
      "ROC: 0.9814312457498023\n",
      "Accuracy: 0.9814407728517079\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model Training Performance\n",
      "ROC: 0.9997951018152472\n",
      "Accuracy: 0.9997948285059411\n",
      "===================================\n",
      "\n",
      "\n",
      "Best Model ('XGBClassifier', 0.9997948285059411)\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "                   models  accuracy  roc_auc_score  f1_score\n",
      "6           XGBClassifier  0.999795       0.999795  0.999795\n",
      "4    KNeighborsClassifier  0.998910       0.998911  0.998909\n",
      "3  DecisionTreeClassifier  0.998388       0.998389  0.998386\n",
      "5      AdaBoostClassifier  0.981441       0.981431  0.981295\n",
      "0      LogisticRegression  0.980520       0.980504  0.980272\n",
      "1         RidgeClassifier  0.932885       0.932801  0.928778\n",
      "2             BernoulliNB  0.920007       0.919895  0.913503\n"
     ]
    }
   ],
   "source": [
    "models={\n",
    "    'LogisticRegression':LogisticRegression(),\n",
    "    'RidgeClassifier':RidgeClassifier(),\n",
    "    'BernoulliNB':BernoulliNB(),\n",
    "    'DecisionTreeClassifier':DecisionTreeClassifier(),\n",
    "    'KNeighborsClassifier':KNeighborsClassifier(),\n",
    "    'AdaBoostClassifier':AdaBoostClassifier(),\n",
    "    #'GradientBoostingClassifier':GradientBoostingClassifier(),\n",
    "    #'BaggingClassifier':BaggingClassifier(),\n",
    "    #'RandomForestClassifier':RandomForestClassifier(),\n",
    "    #'SVC':SVC(),\n",
    "    'XGBClassifier':XGBClassifier()\n",
    "}\n",
    "model_list=[]\n",
    "roc=[]\n",
    "acc = []\n",
    "f1 = []\n",
    "performance = []\n",
    "for i in range(len(list(models))):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    #Make Predictions\n",
    "    y_pred=model.predict(X_test)\n",
    "\n",
    "    accuracy , roc_score  , f_1_score =evaluate_model(y_test,y_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    roc.append(roc_score)\n",
    "    acc.append(accuracy)\n",
    "    f1.append(f_1_score)\n",
    "    performance.append((list(models.keys())[i] , accuracy ))\n",
    "\n",
    "\n",
    "    print('Model Training Performance')\n",
    "    print(\"ROC:\",roc_score)\n",
    "    print(\"Accuracy:\",accuracy)\n",
    "\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')\n",
    "\n",
    "print(\"Best Model\" , sorted(performance , key = lambda x: x[1])[-1])\n",
    "model = models[sorted(performance , key = lambda x: x[1])[-1][0]]\n",
    "print(model)\n",
    "\n",
    "metrics = pd.DataFrame({\"models\": model_list , \"accuracy\" : acc , \"roc_auc_score\": roc , \"f1_score\" : f1}).sort_values('accuracy',ascending=False)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.999795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.998910</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.998909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.998388</td>\n",
       "      <td>0.998389</td>\n",
       "      <td>0.998386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.981441</td>\n",
       "      <td>0.981431</td>\n",
       "      <td>0.981295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.980520</td>\n",
       "      <td>0.980504</td>\n",
       "      <td>0.980272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.932885</td>\n",
       "      <td>0.932801</td>\n",
       "      <td>0.928778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.920007</td>\n",
       "      <td>0.919895</td>\n",
       "      <td>0.913503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   models  accuracy  roc_auc_score  f1_score\n",
       "6           XGBClassifier  0.999795       0.999795  0.999795\n",
       "4    KNeighborsClassifier  0.998910       0.998911  0.998909\n",
       "3  DecisionTreeClassifier  0.998388       0.998389  0.998386\n",
       "5      AdaBoostClassifier  0.981441       0.981431  0.981295\n",
       "0      LogisticRegression  0.980520       0.980504  0.980272\n",
       "1         RidgeClassifier  0.932885       0.932801  0.928778\n",
       "2             BernoulliNB  0.920007       0.919895  0.913503"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEEP LEARNING WITH TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting X_train to train and validation\n",
    "X_train , X_val , y_train , y_val = train_test_split(X_train,y_train,test_size=0.3,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((278628, 30), (119413, 30), (170589, 30))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating layers of ANN\n",
    "LAYERS = [tf.keras.layers.Flatten(input_shape=[30,], name = 'inputLayer'),\n",
    "          tf.keras.layers.Dense(300 , activation = 'relu' , name = \"hiddenLayer1\"),\n",
    "          tf.keras.layers.BatchNormalization(),\n",
    "          tf.keras.layers.Dense(100 , activation = \"relu\" , name = 'hiddenLayer2'),\n",
    "          tf.keras.layers.Dense(10, activation = \"relu\" , name = \"hiddenLayer3\"),\n",
    "          tf.keras.layers.BatchNormalization(),\n",
    "          tf.keras.layers.Dense(1, activation = \"sigmoid\" , name = \"outputLayer\")]\n",
    "model_clf = tf.keras.models.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x237184bd6d0>,\n",
       " <keras.layers.core.dense.Dense at 0x237184bd370>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x237184bd430>,\n",
       " <keras.layers.core.dense.Dense at 0x237184d3c40>,\n",
       " <keras.layers.core.dense.Dense at 0x23718482880>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x237184d36a0>,\n",
       " <keras.layers.core.dense.Dense at 0x237184c7160>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clf.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputLayer (Flatten)        (None, 30)                0         \n",
      "                                                                 \n",
      " hiddenLayer1 (Dense)        (None, 300)               9300      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " hiddenLayer2 (Dense)        (None, 100)               30100     \n",
      "                                                                 \n",
      " hiddenLayer3 (Dense)        (None, 10)                1010      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " outputLayer (Dense)         (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,661\n",
      "Trainable params: 41,041\n",
      "Non-trainable params: 620\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_FUNCTION = \"binary_crossentropy\" # use => tf.losses.sparse_categorical_crossentropy\n",
    "OPTIMIZER = \"SGD\" # or use with custom learning rate => tf.keras.optimizers.SGD(0.02)\n",
    "METRICS = [\"accuracy\"]\n",
    "\n",
    "model_clf.compile(loss=LOSS_FUNCTION,\n",
    "                  optimizer=OPTIMIZER,\n",
    "                  metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "93/93 [==============================] - 10s 113ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
      "Epoch 2/30\n",
      "93/93 [==============================] - 11s 115ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
      "Epoch 3/30\n",
      "93/93 [==============================] - 8s 87ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "Epoch 4/30\n",
      "93/93 [==============================] - 9s 95ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
      "Epoch 5/30\n",
      "93/93 [==============================] - 11s 123ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
      "Epoch 6/30\n",
      "93/93 [==============================] - 11s 115ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
      "Epoch 7/30\n",
      "93/93 [==============================] - 10s 112ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
      "Epoch 8/30\n",
      "93/93 [==============================] - 10s 113ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
      "Epoch 9/30\n",
      "93/93 [==============================] - 11s 124ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
      "Epoch 10/30\n",
      "93/93 [==============================] - 12s 132ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "Epoch 11/30\n",
      "93/93 [==============================] - 12s 131ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "Epoch 12/30\n",
      "93/93 [==============================] - 9s 96ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "Epoch 13/30\n",
      "93/93 [==============================] - 8s 89ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "Epoch 14/30\n",
      "93/93 [==============================] - 10s 108ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "Epoch 15/30\n",
      "93/93 [==============================] - 8s 88ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 16/30\n",
      "93/93 [==============================] - 12s 134ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 17/30\n",
      "93/93 [==============================] - 11s 123ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 18/30\n",
      "93/93 [==============================] - 12s 130ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 19/30\n",
      "93/93 [==============================] - 12s 130ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 20/30\n",
      "93/93 [==============================] - 12s 132ms/step - loss: 9.9470e-04 - accuracy: 0.9998 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "Epoch 21/30\n",
      "93/93 [==============================] - 13s 141ms/step - loss: 9.8860e-04 - accuracy: 0.9998 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "Epoch 22/30\n",
      "93/93 [==============================] - 8s 89ms/step - loss: 9.7682e-04 - accuracy: 0.9998 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "Epoch 23/30\n",
      "93/93 [==============================] - 12s 131ms/step - loss: 9.7152e-04 - accuracy: 0.9998 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "Epoch 24/30\n",
      "93/93 [==============================] - 13s 136ms/step - loss: 9.5007e-04 - accuracy: 0.9998 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "Epoch 25/30\n",
      "93/93 [==============================] - 9s 93ms/step - loss: 9.5051e-04 - accuracy: 0.9998 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "Epoch 26/30\n",
      "93/93 [==============================] - 12s 133ms/step - loss: 9.3870e-04 - accuracy: 0.9999 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "Epoch 27/30\n",
      "93/93 [==============================] - 12s 134ms/step - loss: 9.3426e-04 - accuracy: 0.9999 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "Epoch 28/30\n",
      "93/93 [==============================] - 11s 114ms/step - loss: 9.2647e-04 - accuracy: 0.9998 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "Epoch 29/30\n",
      "93/93 [==============================] - 12s 134ms/step - loss: 9.2389e-04 - accuracy: 0.9999 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "Epoch 30/30\n",
      "93/93 [==============================] - 12s 129ms/step - loss: 8.9608e-04 - accuracy: 0.9999 - val_loss: 0.0016 - val_accuracy: 0.9997\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "EPOCHS = 30\n",
    "VALIDATION_SET = (X_val , y_val)\n",
    "\n",
    "history = model_clf.fit(X_train , y_train , epochs = EPOCHS,\n",
    "                        validation_data= VALIDATION_SET , batch_size = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5331/5331 [==============================] - 12s 2ms/step - loss: 0.0016 - accuracy: 0.9996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0016471972921863198, 0.9996424317359924]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clf.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.999573</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.999422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.999659</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>0.999514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.999514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.999713</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.999498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.999731</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.999514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.999752</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.999548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.999556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.999581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.999590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.999792</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.999590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.999598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.999590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.999623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.999623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.999817</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.999623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>0.999632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.999623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.999824</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.999606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.999632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.999831</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.999615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.999831</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.999623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.999615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.999831</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.999632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.999640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.999665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.999673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.999673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.999846</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.999682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.999690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.999690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   0.001799  0.999573  0.002397      0.999422\n",
       "1   0.001581  0.999659  0.002284      0.999514\n",
       "2   0.001466  0.999691  0.002200      0.999514\n",
       "3   0.001393  0.999713  0.002125      0.999498\n",
       "4   0.001344  0.999731  0.002054      0.999514\n",
       "5   0.001289  0.999752  0.001996      0.999548\n",
       "6   0.001255  0.999756  0.001952      0.999556\n",
       "7   0.001211  0.999777  0.001912      0.999581\n",
       "8   0.001200  0.999767  0.001877      0.999590\n",
       "9   0.001167  0.999792  0.001848      0.999590\n",
       "10  0.001140  0.999795  0.001825      0.999598\n",
       "11  0.001106  0.999799  0.001801      0.999590\n",
       "12  0.001106  0.999799  0.001771      0.999623\n",
       "13  0.001091  0.999799  0.001756      0.999623\n",
       "14  0.001065  0.999817  0.001733      0.999623\n",
       "15  0.001062  0.999813  0.001712      0.999632\n",
       "16  0.001035  0.999824  0.001706      0.999623\n",
       "17  0.001009  0.999824  0.001699      0.999606\n",
       "18  0.001019  0.999828  0.001668      0.999632\n",
       "19  0.000995  0.999831  0.001662      0.999615\n",
       "20  0.000989  0.999831  0.001648      0.999623\n",
       "21  0.000977  0.999842  0.001636      0.999615\n",
       "22  0.000972  0.999831  0.001617      0.999632\n",
       "23  0.000950  0.999838  0.001611      0.999640\n",
       "24  0.000951  0.999838  0.001596      0.999665\n",
       "25  0.000939  0.999853  0.001587      0.999673\n",
       "26  0.000934  0.999853  0.001576      0.999673\n",
       "27  0.000926  0.999846  0.001569      0.999682\n",
       "28  0.000924  0.999856  0.001557      0.999690\n",
       "29  0.000896  0.999860  0.001553      0.999690"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
